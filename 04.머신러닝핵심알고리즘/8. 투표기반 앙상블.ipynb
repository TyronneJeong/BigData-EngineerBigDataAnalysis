{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b57b53b6",
   "metadata": {},
   "source": [
    "# 8. 투표기반 앙상블\n",
    "\n",
    "## 8.1 핵심 개념\n",
    "\n",
    "**투표기반 앙상블(Voting Ensemble)은 여러 분류기를 학습 시킨 후 각각의 분류기가 예측하는 레이블의 범주중 가장 높은 예측율 보이는 케이스를 추출**하여 예측값을 생성 하는 방법입니다.\n",
    "\n",
    "![투표기반앙상블](./extrafiles/voting.png)\n",
    "\n",
    "투표기반 앙상블은 범주기반의 분류(Hard Leaner와 확률 기반의 분류(Soft Leaner) 모두 가능합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb60513",
   "metadata": {},
   "source": [
    "## 8.2 scikit-learn\n",
    "\n",
    "**투표기반 앙상블은 sklearn.ensemble 패키지**에 속해 있습니다. **분류 알고리즘으로는 VotingClassifier, 회귀분석 알고리즘으로는 VotingRegressor** 가 있습니다.\n",
    "\n",
    "\n",
    "|sklearn.ensemble|Ensemble Methods|\n",
    "|:--|:--|\n",
    "|skleanr.ensemble.RandomForestClassifier() |A random forest classifier. |\n",
    "|skleanr.ensemble.RandomForestRegressor() |A random forest regressor. |\n",
    "|skleanr.ensemble.RandomTreeEmbedding() |An ensemble of totally random trees.|\n",
    "|skleanr.ensemble.StackingClassifier() |Stack of estimators with a final classifier.|\n",
    "|skleanr.ensemble.StackingRegressor() |Stack of esimators with a final regressor. |\n",
    "|sklearn.ensemble.VotingClassifier() |Soft Voting/Majority Rule classifier for unfittied estimators. |\n",
    "|sklearn.ensemble.VotingRegressor() |Prediction voting regressor for unfitted estimators. |\n",
    "|sklearn.ensemble.HistGradientBoostingRegressor() |Histogram-based Gradient Boosting Regression Tree. |\n",
    "|sklearn.ensemble.HistGradientBoostingClassifier() |Histogram-based Gradient Boosting Classification Tree. |\n",
    "\n",
    "\n",
    "**VotingClassifier** 에서의 하이퍼파라미터는 vote 입니다. 범주(hard), 확률(soft) 기반으로 투표를 할지를 결정 합니다.  \n",
    "**VotingRegressor** 에서는 하이퍼 파라미터가 존재하지 않습니다.\n",
    "\n",
    "|Hyper Parameter||\n",
    "|:--|:--|\n",
    "|Voting|hardm soft (Classifier 에서만)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0064f77a",
   "metadata": {},
   "source": [
    "## 8.3 분석 코드\n",
    "\n",
    "### Part1. 분류(Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd0148bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['code', 'Clump_Thickness', 'Cell_Size', 'Cell_Shape',\n",
      "       'Marginal_Adhesion', 'Single_Epithelial_Cell_Size', 'Bare_Nuclei',\n",
      "       'Bland_Chromatin', 'Normal_Nucleoli', 'Mitoses', 'Class'],\n",
      "      dtype='object')\n",
      "Class    0.349609\n",
      "dtype: float64\n",
      "Class    0.350877\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 경고레벨조정\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 데이터 로드\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"./extrafiles/breast-cancer-wisconsin.csv\", encoding='utf-8')\n",
    "\n",
    "# 컬럼정보 확인\n",
    "print(data.columns)\n",
    "\n",
    "# 독립변수/ 종속변수 분리\n",
    "X = data[['Clump_Thickness', 'Cell_Size', 'Cell_Shape',\n",
    "       'Marginal_Adhesion', 'Single_Epithelial_Cell_Size', 'Bare_Nuclei',\n",
    "       'Bland_Chromatin', 'Normal_Nucleoli', 'Mitoses']]\n",
    "y = data[['Class']]\n",
    "\n",
    "# train-test data 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "# stratify 효과 - 범주형 변수를 유사한 비율로 train / test 데이터로 분리시켜 준다.\n",
    "print(y_train.mean())\n",
    "print(y_test.mean())\n",
    "\n",
    "# 표준화 작업 - MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_scaled_train = scaler.transform(X_train)\n",
    "X_scaled_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a07e6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(random_state=42)),\n",
       "                             ('rf', RandomForestClassifier(random_state=42)),\n",
       "                             ('svc', SVC(random_state=42))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 투표기반 앙상블\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "logit_model = LogisticRegression(random_state=42)\n",
    "rnf_model = RandomForestClassifier(random_state=42)\n",
    "svm_model = SVC(random_state=42)\n",
    "\n",
    "voting_hard = VotingClassifier(\n",
    "    estimators=[('lr', logit_model), ('rf', rnf_model), ('svc', svm_model)], voting='hard'\n",
    ")\n",
    "\n",
    "voting_hard.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d62053f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression     : 0.9591\n",
      "RandomForestClassifier : 0.9649\n",
      "SVC                    : 0.9649\n",
      "VotingClassifier       : 0.9649\n"
     ]
    }
   ],
   "source": [
    "# 정확도 계산\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 각 알고리즘별 정확도 출력\n",
    "for clf in (logit_model, rnf_model, svm_model, voting_hard):\n",
    "    clf.fit(X_scaled_train, y_train)\n",
    "    y_pred = clf.predict(X_scaled_test)\n",
    "    print('{:22} : {:.4f}'.format(clf.__class__.__name__, accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82772b0",
   "metadata": {},
   "source": [
    "**[각 모델별 분류 정확도 산출]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a508cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로지스틱 분류기 훈련데이터 오차행렬 : \n",
      " [[328   5]\n",
      " [  9 170]]\n",
      "\n",
      "로지스틱 분류기 테스트데이터 오차행렬 : \n",
      " [[106   5]\n",
      " [  2  58]]\n"
     ]
    }
   ],
   "source": [
    "# 로지스틱 회귀모델 혼동행렬 계산\n",
    "from sklearn.metrics import confusion_matrix\n",
    "log_pred_train = logit_model.predict(X_scaled_train)\n",
    "log_confusion_train = confusion_matrix(y_train, log_pred_train)\n",
    "print(\"로지스틱 분류기 훈련데이터 오차행렬 : \\n\", log_confusion_train)\n",
    "\n",
    "log_pred_test = logit_model.predict(X_scaled_test)\n",
    "log_confusion_test = confusion_matrix(y_test, log_pred_test)\n",
    "print(\"\\n로지스틱 분류기 테스트데이터 오차행렬 : \\n\", log_confusion_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf1f7e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "서포트벡터머신 분류기 훈련데이터 오차행렬 : \n",
      " [[329   4]\n",
      " [  4 175]]\n",
      "\n",
      "서포트벡터머신 분류기 테스트데이터 오차행렬 : \n",
      " [[106   5]\n",
      " [  1  59]]\n"
     ]
    }
   ],
   "source": [
    "# SVM 혼동행렬 계산\n",
    "from sklearn.metrics import confusion_matrix\n",
    "svm_pred_train = svm_model.predict(X_scaled_train)\n",
    "svm_confusion_train = confusion_matrix(y_train, svm_pred_train)\n",
    "print(\"서포트벡터머신 분류기 훈련데이터 오차행렬 : \\n\", svm_confusion_train)\n",
    "\n",
    "svm_pred_test = svm_model.predict(X_scaled_test)\n",
    "svm_confusion_test = confusion_matrix(y_test, svm_pred_test)\n",
    "print(\"\\n서포트벡터머신 분류기 테스트데이터 오차행렬 : \\n\", svm_confusion_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c0a04d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤포레스트 분류기 훈련데이터 오차행렬 : \n",
      " [[333   0]\n",
      " [  0 179]]\n",
      "\n",
      "랜덤포레스트 분류기 테스트데이터 오차행렬 : \n",
      " [[106   5]\n",
      " [  1  59]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest 혼동행렬 계산\n",
    "from sklearn.metrics import confusion_matrix\n",
    "rnf_pred_train = rnf_model.predict(X_scaled_train)\n",
    "rnf_confusion_train = confusion_matrix(y_train, rnf_pred_train)\n",
    "print(\"랜덤포레스트 분류기 훈련데이터 오차행렬 : \\n\", rnf_confusion_train)\n",
    "\n",
    "rnf_pred_test = rnf_model.predict(X_scaled_test)\n",
    "rnf_confusion_test = confusion_matrix(y_test, rnf_pred_test)\n",
    "print(\"\\n랜덤포레스트 분류기 테스트데이터 오차행렬 : \\n\", rnf_confusion_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3012af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "투표 분류기 훈련데이터 오차행렬 : \n",
      " [[329   4]\n",
      " [  4 175]]\n",
      "\n",
      "투표 분류기 테스트데이터 오차행렬 : \n",
      " [[106   5]\n",
      " [  1  59]]\n"
     ]
    }
   ],
   "source": [
    "# voting hard 혼동행렬 계산\n",
    "from sklearn.metrics import confusion_matrix\n",
    "voting_pred_train = voting_hard.predict(X_scaled_train)\n",
    "voting_confusion_train = confusion_matrix(y_train, voting_pred_train)\n",
    "print(\"투표 분류기 훈련데이터 오차행렬 : \\n\", voting_confusion_train)\n",
    "\n",
    "voting_pred_test = voting_hard.predict(X_scaled_test)\n",
    "voting_confusion_test = confusion_matrix(y_test, voting_pred_test)\n",
    "print(\"\\n투표 분류기 테스트데이터 오차행렬 : \\n\", voting_confusion_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ec17c5",
   "metadata": {},
   "source": [
    "**[종합정리]**\n",
    "\n",
    "분석 데이터 에서는 개별 분류 알고리즘과 거의 유사한 결과를 보였습니다만 **일반적으로 앙상블은 개별 알고리즘 조합이 좋으면 좀 더 나은 결과를 보장**합니다. 또 <u>범주(hard) 보다는 확률(soft) 투표 방식이 보다 높은 정확도</u>를 보여줍니다. **실전에 자주 사용되는 방식이므로 반드시 익혀 두어야 합니다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d052a090",
   "metadata": {},
   "source": [
    "### Part2. 회귀(Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1093b541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['housing_age', 'income', 'bedrooms', 'households', 'rooms',\n",
      "       'house_value'],\n",
      "      dtype='object')\n",
      "Index(['income', 'bedrooms', 'households', 'rooms'], dtype='object')\n",
      "house_value    189260.967812\n",
      "dtype: float64\n",
      "house_value    188391.001357\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "data2 = pd.read_csv('./extrafiles/house_price.csv', encoding='utf-8')\n",
    "\n",
    "print(data2.columns)\n",
    "\n",
    "X = data2[data2.columns[1:5]]\n",
    "y = data2[['house_value']]\n",
    "\n",
    "print(X.columns)\n",
    "\n",
    "# train-test data 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# stratify 효과 - 범주형 변수를 유사한 비율로 train / test 데이터로 분리시켜 준다.\n",
    "print(y_train.mean())\n",
    "print(y_test.mean())\n",
    "\n",
    "# 표준화 작업 - MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_scaled_train = scaler.transform(X_train)\n",
    "X_scaled_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04c19bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingRegressor(estimators=[('lr', LinearRegression()),\n",
       "                            ('rf', RandomForestRegressor(random_state=42))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 투표기반 앙상블 모델 적용\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "linear_model = LinearRegression()\n",
    "rnf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "voting_regressor = VotingRegressor(\n",
    "    estimators=[('lr', linear_model), ('rf', rnf_model)] # 회귀분석에서는 voting type 이 존재하지 않는다.\n",
    ")\n",
    "\n",
    "voting_regressor.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5778434c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7962532705428835"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련 데이터 모델 적용\n",
    "pred_train = voting_regressor.predict(X_scaled_train)\n",
    "voting_regressor.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d3c4858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5936371957936408"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 데이터 모델 적용\n",
    "pred_test = voting_regressor.predict(X_scaled_test)\n",
    "voting_regressor.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01df8541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈  련데이터 RMSE: 43082.050654857834\n",
      "테스트데이터 RMSE: 60942.385243534896\n"
     ]
    }
   ],
   "source": [
    "# 회귀분석의 지표 R Square n RMSE\n",
    "# RMSE (Root Mean Squared Error)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "MSE_train = mean_squared_error(y_train, pred_train)\n",
    "MSE_test = mean_squared_error(y_test, pred_test)\n",
    "print(\"훈  련데이터 RMSE:\", np.sqrt(MSE_train))\n",
    "print(\"테스트데이터 RMSE:\", np.sqrt(MSE_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c757dbb2",
   "metadata": {},
   "source": [
    "**[종합정리]**\n",
    "\n",
    "회귀문제에서 투표기반 앙상블로 2개 알고리즘만 조합하였음에도 정확도가 개별 알고리즘을 적용할때 보다 높게 나타났다. 개별 알고리즘의 하이퍼 파라미터를 효과적으로 튜닝한다면 더 좋은 결과도 기대할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d434e207",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
