{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "909e233f",
   "metadata": {},
   "source": [
    "# 8. 투표기반 앙상블\n",
    "\n",
    "## 8.1 핵심 개념\n",
    "\n",
    "**투표기반 앙상블(Voting Ensemble)은 여러 분류기를 학습 시킨 후 각각의 분류기가 예측하는 레이블의 범주중 가장 높은 예측율 보이는 케이스를 추출**하여 예측값을 생성 하는 방법입니다.\n",
    "\n",
    "![투표기반앙상블](./extrafiles/voting.png)\n",
    "\n",
    "투표기반 앙상블은 범주기반의 분류(Hard Leaner와 확률 기반의 분류(Soft Leaner) 모두 가능합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f2e007",
   "metadata": {},
   "source": [
    "## 8.2 scikit-learn\n",
    "\n",
    "**투표기반 앙상블은 sklearn.ensemble 패키지**에 속해 있습니다. **분류 알고리즘으로는 VotingClassifier, 회귀분석 알고리즘으로는 VotingRegressor** 가 있습니다.\n",
    "\n",
    "\n",
    "|sklearn.ensemble|Ensemble Methods|\n",
    "|:--|:--|\n",
    "|skleanr.ensemble.RandomForestClassifier() |A random forest classifier. |\n",
    "|skleanr.ensemble.RandomForestRegressor() |A random forest regressor. |\n",
    "|skleanr.ensemble.RandomTreeEmbedding() |An ensemble of totally random trees.|\n",
    "|skleanr.ensemble.StackingClassifier() |Stack of estimators with a final classifier.|\n",
    "|skleanr.ensemble.StackingRegressor() |Stack of esimators with a final regressor. |\n",
    "|sklearn.ensemble.VotingClassifier() |Soft Voting/Majority Rule classifier for unfittied estimators. |\n",
    "|sklearn.ensemble.VotingRegressor() |Prediction voting regressor for unfitted estimators. |\n",
    "|sklearn.ensemble.HistGradientBoostingRegressor() |Histogram-based Gradient Boosting Regression Tree. |\n",
    "|sklearn.ensemble.HistGradientBoostingClassifier() |Histogram-based Gradient Boosting Classification Tree. |\n",
    "\n",
    "\n",
    "**VotingClassifier** 에서의 하이퍼파라미터는 vote 입니다. 범주(hard), 확률(soft) 기반으로 투표를 할지를 결정 합니다.  \n",
    "**VotingRegressor** 에서는 하이퍼 파라미터가 존재하지 않습니다.\n",
    "\n",
    "|Hyper Parameter||\n",
    "|:--|:--|\n",
    "|Voting|hardm soft (Classifier 에서만)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2a83a6",
   "metadata": {},
   "source": [
    "## 8.3 분석 코드\n",
    "\n",
    "### Part1. 분류(Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57818246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['code', 'Clump_Thickness', 'Cell_Size', 'Cell_Shape',\n",
      "       'Marginal_Adhesion', 'Single_Epithelial_Cell_Size', 'Bare_Nuclei',\n",
      "       'Bland_Chromatin', 'Normal_Nucleoli', 'Mitoses', 'Class'],\n",
      "      dtype='object')\n",
      "Class    0.349609\n",
      "dtype: float64\n",
      "Class    0.350877\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 경고레벨조정\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 데이터 로드\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"./extrafiles/breast-cancer-wisconsin.csv\", encoding='utf-8')\n",
    "\n",
    "# 컬럼정보 확인\n",
    "print(data.columns)\n",
    "\n",
    "# 독립변수/ 종속변수 분리\n",
    "X = data[['Clump_Thickness', 'Cell_Size', 'Cell_Shape',\n",
    "       'Marginal_Adhesion', 'Single_Epithelial_Cell_Size', 'Bare_Nuclei',\n",
    "       'Bland_Chromatin', 'Normal_Nucleoli', 'Mitoses']]\n",
    "y = data[['Class']]\n",
    "\n",
    "# train-test data 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "# stratify 효과 - 범주형 변수를 유사한 비율로 train / test 데이터로 분리시켜 준다.\n",
    "print(y_train.mean())\n",
    "print(y_test.mean())\n",
    "\n",
    "# 표준화 작업 - MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_scaled_train = scaler.transform(X_train)\n",
    "X_scaled_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6cf0b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(random_state=42)),\n",
       "                             ('rf', RandomForestClassifier(random_state=42)),\n",
       "                             ('svc', SVC(random_state=42))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 투표기반 앙상블\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "logit_model = LogisticRegression(random_state=42)\n",
    "rnf_model = RandomForestClassifier(random_state=42)\n",
    "svm_model = SVC(random_state=42)\n",
    "\n",
    "voting_hard = VotingClassifier(\n",
    "    estimators=[('lr', logit_model), ('rf', rnf_model), ('svc', svm_model)], voting='hard'\n",
    ")\n",
    "\n",
    "voting_hard.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f7bdbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.9590643274853801\n",
      "RandomForestClassifier 0.9649122807017544\n",
      "SVC 0.9649122807017544\n",
      "VotingClassifier 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "# 정확도 계산\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 각 알고리즘별 정확도 출력\n",
    "for clf in (logit_model, rnf_model, svm_model, voting_hard):\n",
    "    clf.fit(X_scaled_train, y_train)\n",
    "    y_pred = clf.predict(X_scaled_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72dc6aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로지스틱 분류기 훈련데이터 오차행렬 : \n",
      " [[328   5]\n",
      " [  9 170]]\n",
      "\n",
      "로지스틱 분류기 테스트데이터 오차행렬 : \n",
      " [[106   5]\n",
      " [  2  58]]\n"
     ]
    }
   ],
   "source": [
    "# 로지스틱 회귀모델 혼동행렬 계산\n",
    "from sklearn.metrics import confusion_matrix\n",
    "log_pred_train = logit_model.predict(X_scaled_train)\n",
    "log_confusion_train = confusion_matrix(y_train, log_pred_train)\n",
    "print(\"로지스틱 분류기 훈련데이터 오차행렬 : \\n\", log_confusion_train)\n",
    "\n",
    "log_pred_test = logit_model.predict(X_scaled_test)\n",
    "log_confusion_test = confusion_matrix(y_test, log_pred_test)\n",
    "print(\"\\n로지스틱 분류기 테스트데이터 오차행렬 : \\n\", log_confusion_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3615781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로지스틱 분류기 훈련데이터 오차행렬 : \n",
      " [[329   4]\n",
      " [  4 175]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [512, 171]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-ba8717149764>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0msvm_pred_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_scaled_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0msvm_confusion_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvm_pred_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n로지스틱 분류기 테스트데이터 오차행렬 : \\n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvm_confusion_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m     \"\"\"\n\u001b[1;32m--> 296\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    263\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [512, 171]"
     ]
    }
   ],
   "source": [
    "# SVM 혼동행렬 계산\n",
    "from sklearn.metrics import confusion_matrix\n",
    "svm_pred_train = svm_model.predict(X_scaled_train)\n",
    "svm_confusion_train = confusion_matrix(y_train, svm_pred_train)\n",
    "print(\"로지스틱 분류기 훈련데이터 오차행렬 : \\n\", svm_confusion_train)\n",
    "\n",
    "svm_pred_test = svm_model.predict(X_scaled_test)\n",
    "svm_confusion_test = confusion_matrix(y_train, svm_pred_test)\n",
    "print(\"\\n로지스틱 분류기 테스트데이터 오차행렬 : \\n\", svm_confusion_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48b15c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
