{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6875a0a2",
   "metadata": {},
   "source": [
    "# 11. 앙상블 스태킹(Stacking)\n",
    "\n",
    "## 11.1 핵심 개념\n",
    "\n",
    "**스태킹(Stacking)은 데이터셋이 아니라 여러 학습기에서 예측한 예측값(predict value)로 다시 학습 데이터를 만들어 일반화(generalization) 시킨 최종 모델을 구하는 모델**이다. 핵심적인 차이는 데이터셋이 아닌 예측값들로 예측을 한다는 아이디어 이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889cb163",
   "metadata": {},
   "source": [
    "# 11.2 scikit-learn\n",
    "\n",
    "**스태킹은 sklearn.ensemble 패키지**에 속해 있다. **분류 알고리즘으로는 StackingClassifier, 회귀분석 알고리즘으로는 StackingRegressor** 가 있다.\n",
    "\n",
    "\n",
    "|sklearn.ensemble|Ensemble Methods|\n",
    "|:--|:--|\n",
    "|skleanr.ensemble.ExtraTreeRegressor() |An extra-tree regressor. |\n",
    "|skleanr.ensemble.GradientBoostingClassifier() |Gradient Boosting for classification. |\n",
    "|skleanr.ensemble.GradientBoostingRegressor() |Gradient Boosting for regressor.|\n",
    "|skleanr.ensemble.IsolationForest() |Isolation Forest Algorithm. |\n",
    "|skleanr.ensemble.RandomForestClassifier() |A random forest classifier. |\n",
    "|skleanr.ensemble.RandomForestRegressor() |A random forest regressor. |\n",
    "|skleanr.ensemble.RandomTreeEmbedding() |An ensemble of totally random trees.|\n",
    "|**skleanr.ensemble.StackingClassifier()** |Stack of estimators with a final classifier.|\n",
    "|**skleanr.ensemble.StackingRegressor()** |Stack of esimators with a final regressor. |\n",
    "\n",
    "주요 **하이퍼 파라미터이자 여러 알고리즘을 쌓는 옵션은 estimators** 이다.\n",
    "Voting 방법과 유사하게 여러 개별 알고리즘으로 estimator 를 구성한다. **각 개별 알고리즘들이 예측한 값들이 다시 StackingClassifier 와 StackingRegressor 의 학습 데이터가 된다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788a9f93",
   "metadata": {},
   "source": [
    "## 11.3 분석 코드\n",
    "\n",
    "### Part1. 분류(Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e355af23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['code', 'Clump_Thickness', 'Cell_Size', 'Cell_Shape',\n",
      "       'Marginal_Adhesion', 'Single_Epithelial_Cell_Size', 'Bare_Nuclei',\n",
      "       'Bland_Chromatin', 'Normal_Nucleoli', 'Mitoses', 'Class'],\n",
      "      dtype='object')\n",
      "Class    0.349609\n",
      "dtype: float64\n",
      "Class    0.350877\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 경고레벨조정\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 데이터 로드\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"./extrafiles/breast-cancer-wisconsin.csv\", encoding='utf-8')\n",
    "\n",
    "# 컬럼정보 확인\n",
    "print(data.columns)\n",
    "\n",
    "# 독립변수/ 종속변수 분리\n",
    "X = data[['Clump_Thickness', 'Cell_Size', 'Cell_Shape',\n",
    "       'Marginal_Adhesion', 'Single_Epithelial_Cell_Size', 'Bare_Nuclei',\n",
    "       'Bland_Chromatin', 'Normal_Nucleoli', 'Mitoses']]\n",
    "y = data[['Class']]\n",
    "\n",
    "# train-test data 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "# stratify 효과 - 범주형 변수를 유사한 비율로 train / test 데이터로 분리시켜 준다.\n",
    "print(y_train.mean())\n",
    "print(y_test.mean())\n",
    "\n",
    "# 표준화 작업 - MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_scaled_train = scaler.transform(X_train)\n",
    "X_scaled_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0229b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.986328125"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 스태킹 적용\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators = [('rf', RandomForestClassifier(n_estimators=10, random_state=42)), ('svr', SVC(random_state=42))]\n",
    "model = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "model.fit(X_scaled_train, y_train)\n",
    "pred_train = model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5edef55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련데이터 오차행렬 : \n",
      " [[330   3]\n",
      " [  4 175]]\n"
     ]
    }
   ],
   "source": [
    "# 훈련데이터의 혼동행렬 작성\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_train = confusion_matrix(y_train, pred_train)\n",
    "print(\"훈련데이터 오차행렬 : \\n\", confusion_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e064e4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류예측 레포트 : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       333\n",
      "           1       0.98      0.98      0.98       179\n",
      "\n",
      "    accuracy                           0.99       512\n",
      "   macro avg       0.99      0.98      0.98       512\n",
      "weighted avg       0.99      0.99      0.99       512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 훈련데이터의 분류 레포트 작성\n",
    "from sklearn.metrics import classification_report\n",
    "cfreport_train = classification_report(y_train, pred_train)\n",
    "print(\"분류예측 레포트 : \\n\", cfreport_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8c41623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649122807017544"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트데이터 예측결과 생성\n",
    "pred_test = model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a485b5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트데이터 오차행렬 : \n",
      " [[106   5]\n",
      " [  1  59]]\n"
     ]
    }
   ],
   "source": [
    "# 테스트데이터의 혼동행렬 작성\n",
    "confusion_test = confusion_matrix(y_test, pred_test)\n",
    "print(\"테스트데이터 오차행렬 : \\n\", confusion_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b15a14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류예측 레포트 : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       111\n",
      "           1       0.92      0.98      0.95        60\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.96      0.97      0.96       171\n",
      "weighted avg       0.97      0.96      0.97       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 테스트데이터의 분류 레포트 작성\n",
    "from sklearn.metrics import classification_report\n",
    "cfreport_test = classification_report(y_test, pred_test)\n",
    "print(\"분류예측 레포트 : \\n\", cfreport_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387dabfe",
   "metadata": {},
   "source": [
    "**[종합정리]**\n",
    "\n",
    "**스태킹 앙상블은 모델을 어떻게 쌓는가에 따라 결과가 달라진다.** 때문에 모델 순서를 변경하거나 다른 알고리즘을 구성하면 보다 나은 결과를 기대할 수 있따."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d96a06",
   "metadata": {},
   "source": [
    "### Part2. 회귀(Regression)\n",
    "\n",
    "스태킹 회귀분석에서는 선형회귀분석, KNN의 Regressor 2가지를 개별 모델로 설정하고 StackingClassifier의 estimators 로 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2fbcb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['housing_age', 'income', 'bedrooms', 'households', 'rooms',\n",
      "       'house_value'],\n",
      "      dtype='object')\n",
      "Index(['income', 'bedrooms', 'households', 'rooms'], dtype='object')\n",
      "house_value    189260.967812\n",
      "dtype: float64\n",
      "house_value    188391.001357\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "data2 = pd.read_csv('./extrafiles/house_price.csv', encoding='utf-8')\n",
    "\n",
    "print(data2.columns)\n",
    "\n",
    "X = data2[data2.columns[1:5]]\n",
    "y = data2[['house_value']]\n",
    "\n",
    "print(X.columns)\n",
    "\n",
    "# train-test data 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# stratify 효과 - 범주형 변수를 유사한 비율로 train / test 데이터로 분리시켜 준다.\n",
    "print(y_train.mean())\n",
    "print(y_test.mean())\n",
    "\n",
    "# 표준화 작업 - MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_scaled_train = scaler.transform(X_train)\n",
    "X_scaled_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a81ed03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.543404932348004"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 스태킹 알고리즘 적용\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "estimators = [('lr', LinearRegression()), ('knn', KNeighborsRegressor())]\n",
    "model = StackingRegressor(estimators=estimators, final_estimator=RandomForestRegressor(n_estimators=10, random_state=42))\n",
    "model.fit(X_scaled_train, y_train)\n",
    "pred_train = model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "950dbfe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4781188528801523"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 데이터 모델 적용\n",
    "pred_test = model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3366436a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈  련데이터 RMSE: 64493.60476580374\n",
      "테스트데이터 RMSE: 69063.45138802647\n"
     ]
    }
   ],
   "source": [
    "# 회귀분석의 지표 R Square n RMSE\n",
    "# RMSE (Root Mean Squared Error)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "MSE_train = mean_squared_error(y_train, pred_train)\n",
    "MSE_test = mean_squared_error(y_test, pred_test)\n",
    "print(\"훈  련데이터 RMSE:\", np.sqrt(MSE_train))\n",
    "print(\"테스트데이터 RMSE:\", np.sqrt(MSE_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b09a79",
   "metadata": {},
   "source": [
    "**[종합정리]**\n",
    "\n",
    "회귀 문제에서 사용된 개별 알고리즘은 선형회귀와 KNN 의 회귀모델이다. 다만 해당 알고리즘은 기본 알고리즘보다 정확도가 낮게 나타났다. **앙상블 모델은 각 알고리즘을 수행한 후 결과가 좋은 알고리즘과 하이퍼 파라미터로 estimator 를 구성해야 더 좋은 결과를 기대할 수 있다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e391e894",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
