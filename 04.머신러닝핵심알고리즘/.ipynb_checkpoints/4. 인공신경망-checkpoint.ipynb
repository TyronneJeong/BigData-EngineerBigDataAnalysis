{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a4ca467",
   "metadata": {},
   "source": [
    "# 4. 인공신경망\n",
    "\n",
    "## 4.1 핵심 개념\n",
    "\n",
    "**인공신경망은 인간의 뉴런 구조와 활성화 작동원리를 근간으로 input(자극)과 output(반응)의 연관관계를 구현한 알고리즘** 입니다. 전통적인 알고리즘과의 가장 큰 차이는 중간에 은닉층(hidden layer)과 노드들이 깊고 넓게 특성치로부터 분류와 회귀를 더 잘 할수 있도록 특징 추출 및 분류를 확장하는 모양으로 구현된 모델이라는 점 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20542c76",
   "metadata": {},
   "source": [
    "![인공신경망](./extrafiles/neural.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1401a0e1",
   "metadata": {},
   "source": [
    "**퍼셉트론(Perceptron)**\n",
    "\n",
    "1943년 신경과학자 Warren S, McCulloch 와 논리학자 Walter Pitts 가 뇌 신경 세포를 하나의 이진 출력을 가진 논리게이트로 설명함을 근원으로\n",
    "\n",
    "![뉴런](./extrafiles/neuron.jpg)\n",
    "\n",
    "\n",
    "이들은 그림에서의 예시와 같이 입력 신호가 가지돌기(Dendrite)에 도착하면 신경세포 내에서 이 신호들을 하나의 신호로 통합하고 이 값이 특정 임계값을 초과하면 하나의 단일 신호로 축삭돌기(Axon)로 전달되는 것으로 이해했습니다. 이렇게 단순화된 원리로 동작하는 뇌 세포를 **McCulloch-Pitts뉴런(MCP뉴런)**이라고 부릅니다.\n",
    "\n",
    "\n",
    "1959년 코넬 항공 연구소에서 근무하던 Frank Rosenblatt 은 이 MCP 뉴런모델을 기초로 퍼셉트론(Perseptron) 학습규칙이라는 개념을 고안하게 되는데. Rosenblatt은 하나의 MCP 뉴런이 출력신호를 발생시킬지 아닐지 결정하기 위해 **MCP 뉴런으로 들어오는 각 입력값에 곱해지는 가중치 값을 자동적으로 학습 하는 알고리즘**을 제안했습니다.\n",
    "\n",
    "![퍼셉트론](./extrafiles/perceptron.jpg)\n",
    "\n",
    "\n",
    "그림에서 **x0\\~xn은 특성값을 의미하며 여기에 가중치 w0\\~wn 까지를 곱하여 하나의 값으로 만드는 함수를 순입력 함수(net input)** 라고 부릅니다. 그리고 이 순입력 함수의 결과값을 특정 임계값과 비교하여, **순입력 함수 값이 임계치를 넘으면 1, 그렇지 않으면 -1로 출력하는 함수를 정의하는데 이를 활성 함수(Activation function)** 라고 부릅니다.\n",
    "\n",
    "퍼셉트론은 다수의 트레이닝 데이터를 이용하여 일종의 지도 학습을 수행 하는 알고리즘입니다. 트레이닝 데이터에는 데이터의 특성값에 대응되는 실제 결과값을 가지고 있어야 합니다. 앞서 변환된 순입력 함수의 결과값을 활성함수를 거쳐 1과 -1로 분류하게 되는데 이렇게 산출된 예측값이 실제 값과 다르다면 두 값이 같아질때 까지 가중치 w0\\~wn을 업데이트 하게 됩니다.\n",
    "\n",
    "![퍼셉트론](./extrafiles/perceptron2.jpg)\n",
    "\n",
    "여기서 **중간층을 노드 또는 뉴런**이라고 부르며, 입력층은 다른 노드의 출력층으로 부터 연결되는 입력층이며, 해당 노드의 출력층은 다른 노드의 입력층으로 이어지는 층이라고 볼 수 있습니다.\n",
    "\n",
    "이렇게 <u>중간층이 하나의 노드로 구성 되어 중간층과 출력층의 구분이 없는 구조를 단순 또는 단층 퍼셉트론</u>이라고 부릅니다. 그리고 **중간층을 구성하는 노드가 여러개 이고 이런 중간층이 다수로 구성되어 있는 구조를 다층 퍼셉트론**이라고 부릅니다.\n",
    "\n",
    "\n",
    "![다층 퍼셉트론](./extrafiles/perceptron3.jpg)\n",
    "\n",
    "\n",
    "이러한 다층 인공신경망을 학습하는 알고리즘을 딥 러닝(Deep Leaning)이라고 부릅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833b6278",
   "metadata": {},
   "source": [
    "**아달라인(Adaline)**\n",
    "\n",
    "단층 인공 신경망인 퍼셉트론이 발표된 이후 1960년에 Bernard Windrow와 Tedd Hoff 는 퍼셉트론 알고리즘을 향상 시킨 새로운 인공신경망 알고리즘에 대한 논물을 발표 합니다.\n",
    "\n",
    "퍼셉트론과 아달라인의 차이점은 바로 가중치 업데이트를 위한 활성 함수가 다르다는 점 입니다.\n",
    "\n",
    "![아달라인](./extrafiles/adaline.jpg)\n",
    "\n",
    "그림에서 보는바와 같이, 퍼셉트론은 활성 함수가 순입력 함수의 리턴 값을 임계값과 비교후 다음 노드로 전달함과 다르게, **아달라인은 활성 함수는 활성함수의 결과값을 단순 비교가 아닌 순입력 함수의 결과값과 실제 값과의 차이가 최소가 되도록 조정하는 기능을 추가**했다는 점에서 차이가 존재합니다. 그리고  오차항의 값을 최소가 되도록 하는 방법으로 경사하강법(gradient descent)라 불리는 최적화 알고리즘을 통해 가중치를 조정하게 됩니다.\n",
    "\n",
    "이렇게 이 인공신경망은 Adaptive Linear Neuron, 줄여서 Adaline(아달라인)이라고 부르게 되며, 아달라인은 분류를 보다 발전된 머신러닝 알고리즘인 회귀(Regression), 로지스틱 회귀(Logistic Regression), SVM(Support Vector Machine) 에 대한 알고리즘 토대를 마련하게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a35a1cf",
   "metadata": {},
   "source": [
    "**인공신경망의 기본모델은 다층 퍼셉트론을 수행하는 것**입니다. 입력층과 출력층은 각각 특성치(X), 와 레이블(y)을 말합니다. 그리고 중간의 은닉층은 몇개로 둘 것인지, 그 은닉층에 노드는 얼마나 둘 것인지가 하이퍼파라미터가 됩니다.\n",
    "\n",
    "이 외에도 다양한 파라미터들이 존재합니다.  \n",
    "**학습율(learning rate)** 은 어느정도의 간격으로 가중치를 좁혀 갈 것인지를 정할 수 있습니다.  \n",
    "**활성함수(activation function)** 로는 sigmoid, Relu, sgd, adma 등의 방법이 있습니다.  \n",
    "**학습횟수(epoch)** 은 해당 과정을 반복 실행 할 횟수 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d29e68",
   "metadata": {},
   "source": [
    "## 4.2 scikit-learn\n",
    "\n",
    "인공신경망은 **sklearn.neural_network** 패키지에 있습니다.\n",
    "이중 분류 <u>알고리즘으로는 MLPClassifier</u> 가 있고, <u>회귀 알고리즘으로는 MLPRegressor</u> 가 있습니다.\n",
    "\n",
    "|sklearn.neural_network|Neural network models|\n",
    "|:--|:--|\n",
    "|neural_network.BernoulliRBM() |Bernoulli Rstricted Bolzmann Machnine (RBM)|\n",
    "|neural_network.MLPClassifier() |Multi-layer Perceptron classifier.|\n",
    "|neural_network.MLPRegressor() |Multi-layer Perceptron regressor. |\n",
    "\n",
    "MLP 알고리즘은 옵션이 상당히 많습니다. 딥러닝의 원조인 인공신경망은 기본적인 뼈대가 딥러닝과 동일 합니다. 따라서 많은 하이퍼 파라미터를 조정 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "247ee83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17116019523698444932\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# GPU 가속 사용 옵션\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.test.is_built_with_cuda()) # cuda 사용 가능 여부 확인\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526ddaeb",
   "metadata": {},
   "source": [
    "## 4.3 분석 코드\n",
    "\n",
    "### Part1. 분류(Classification)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "580d19cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['code', 'Clump_Thickness', 'Cell_Size', 'Cell_Shape',\n",
      "       'Marginal_Adhesion', 'Single_Epithelial_Cell_Size', 'Bare_Nuclei',\n",
      "       'Bland_Chromatin', 'Normal_Nucleoli', 'Mitoses', 'Class'],\n",
      "      dtype='object')\n",
      "Class    0.349609\n",
      "dtype: float64\n",
      "Class    0.350877\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 경고레벨조정\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 데이터 로드\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"./extrafiles/breast-cancer-wisconsin.csv\", encoding='utf-8')\n",
    "\n",
    "# 컬럼정보 확인\n",
    "print(data.columns)\n",
    "\n",
    "# 독립변수/ 종속변수 분리\n",
    "X = data[['Clump_Thickness', 'Cell_Size', 'Cell_Shape',\n",
    "       'Marginal_Adhesion', 'Single_Epithelial_Cell_Size', 'Bare_Nuclei',\n",
    "       'Bland_Chromatin', 'Normal_Nucleoli', 'Mitoses']]\n",
    "y = data[['Class']]\n",
    "\n",
    "# train-test data 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "# stratify 효과 - 범주형 변수를 유사한 비율로 train / test 데이터로 분리시켜 준다.\n",
    "print(y_train.mean())\n",
    "print(y_test.mean())\n",
    "\n",
    "# 표준화 작업 - MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_scaled_train = scaler.transform(X_train)\n",
    "X_scaled_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eac8831a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.974609375"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인공신경망 알고리즘 적용\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "model=MLPClassifier()\n",
    "model.fit(X_scaled_train, y_train)\n",
    "pred_train = model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c14c3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련데이터 오차행렬 : \n",
      " [[328   5]\n",
      " [  8 171]]\n"
     ]
    }
   ],
   "source": [
    "# 훈련데이터 혼동행렬 정보 확인\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_train = confusion_matrix(y_train, pred_train)\n",
    "print(\"훈련데이터 오차행렬 : \\n\", confusion_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f490ef",
   "metadata": {},
   "source": [
    "![혼동행렬](./extrafiles/matrix.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "196426c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류예측 레포트 : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       333\n",
      "           1       0.97      0.96      0.96       179\n",
      "\n",
      "    accuracy                           0.97       512\n",
      "   macro avg       0.97      0.97      0.97       512\n",
      "weighted avg       0.97      0.97      0.97       512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 훈련데이터 분류 레포트 작성\n",
    "from sklearn.metrics import classification_report\n",
    "cfreport_train = classification_report(y_train, pred_train)\n",
    "print(\"분류예측 레포트 : \\n\", cfreport_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "857ecf3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9590643274853801"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트데이터 예측결과 생성\n",
    "pred_test = model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55146c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트데이터 오차행렬 : \n",
      " [[106   5]\n",
      " [  2  58]]\n"
     ]
    }
   ],
   "source": [
    "# 테스트데이터 분류 레포트 작성\n",
    "confusion_test = confusion_matrix(y_test, pred_test)\n",
    "print(\"테스트데이터 오차행렬 : \\n\", confusion_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cffd0a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류예측 레포트 : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97       111\n",
      "           1       0.92      0.97      0.94        60\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.95      0.96      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 분류예측 레포트 작성\n",
    "cfreport_test = classification_report(y_test, pred_test)\n",
    "print(\"분류예측 레포트 : \\n\", cfreport_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a47b613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=MLPClassifier(),\n",
       "             param_grid={'activation': ['tanh', 'relu'],\n",
       "                         'hidden_layer_sizes': [10, 30, 50, 100],\n",
       "                         'solver': ['sgd', 'adam']})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 하이퍼 파라미터 튜닝 - Grid Search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'hidden_layer_sizes':[10, 30, 50, 100], 'solver':['sgd', 'adam'], 'activation':['tanh', 'relu']}\n",
    "grid_search = GridSearchCV(MLPClassifier(), param_grid, cv=5)\n",
    "grid_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73397770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter : {'activation': 'relu', 'hidden_layer_sizes': 50, 'solver': 'adam'}\n",
      "Best Score : 0.9746\n",
      "Test set Score : 0.9649\n"
     ]
    }
   ],
   "source": [
    "# 파라미터 튜닝 결과 확인\n",
    "print(\"Best Parameter : {}\".format(grid_search.best_params_))\n",
    "print(\"Best Score : {:.4f}\".format(grid_search.best_score_))\n",
    "print(\"Test set Score : {:.4f}\".format(grid_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "455ff80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=MLPClassifier(),\n",
       "                   param_distributions={'activation': ['tanh', 'relu'],\n",
       "                                        'hidden_layer_sizes': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001DACAD17280>,\n",
       "                                        'solver': ['sgd', 'adam']})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 하이퍼 파라미터 튜닝2 - Randomized Search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_distribs = {'hidden_layer_sizes':randint(low=10, high=100), 'solver':['sgd', 'adam'], 'activation':['tanh', 'relu']}\n",
    "\n",
    "random_search = RandomizedSearchCV(MLPClassifier(), param_distributions=param_distribs, n_iter=10, cv=5)\n",
    "random_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "780dc989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter : {'activation': 'tanh', 'hidden_layer_sizes': 17, 'solver': 'adam'}\n",
      "Best Score : 0.9746\n",
      "Test set Score : 0.9532\n"
     ]
    }
   ],
   "source": [
    "# 파라미터 튜닝 결과값 확인\n",
    "print(\"Best Parameter : {}\".format(random_search.best_params_))\n",
    "print(\"Best Score : {:.4f}\".format(random_search.best_score_))\n",
    "print(\"Test set Score : {:.4f}\".format(random_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2cb831",
   "metadata": {},
   "source": [
    "### Part2. 회귀(Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "491b0856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['housing_age', 'income', 'bedrooms', 'households', 'rooms',\n",
      "       'house_value'],\n",
      "      dtype='object')\n",
      "Index(['income', 'bedrooms', 'households', 'rooms'], dtype='object')\n",
      "house_value    189260.967812\n",
      "dtype: float64\n",
      "house_value    188391.001357\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "data2 = pd.read_csv('./extrafiles/house_price.csv', encoding='utf-8')\n",
    "\n",
    "print(data2.columns)\n",
    "\n",
    "X = data2[data2.columns[1:5]]\n",
    "y = data2[['house_value']]\n",
    "\n",
    "print(X.columns)\n",
    "\n",
    "# train-test data 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# stratify 효과 - 범주형 변수를 유사한 비율로 train / test 데이터로 분리시켜 준다.\n",
    "print(y_train.mean())\n",
    "print(y_test.mean())\n",
    "\n",
    "# 표준화 작업 - MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_scaled_train = scaler.transform(X_train)\n",
    "X_scaled_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82b6e30e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.7196469329742503"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLRegressor 적용\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "model=MLPRegressor()\n",
    "model.fit(X_scaled_train, y_train)\n",
    "pred_train = model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53435caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.6777040392872293"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트데이터 베이지안 릿지 적용\n",
    "pred_test = model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b62ba79",
   "metadata": {},
   "source": [
    "※ 훈련데이터 밑 테스트 의 정확도가 -271%, -267%가 나왔다. <u>정확도에 음수가 나오는 것은 매우 잘못된 결과이다.</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bb459ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈  련데이터 RMSE :  184078.00688973855\n",
      "테스트데이터 RMSE :  183337.3131091806\n"
     ]
    }
   ],
   "source": [
    "# RMSE (Root Mean Squared Error)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "MSE_train = mean_squared_error(y_train, pred_train)\n",
    "MSE_test = mean_squared_error(y_test, pred_test)\n",
    "print(\"훈  련데이터 RMSE : \", np.sqrt(MSE_train))\n",
    "print(\"테스트데이터 RMSE : \", np.sqrt(MSE_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2d70ce",
   "metadata": {},
   "source": [
    "※ 오차율 역시 다른 알고리즘들에 비해 매우 크다.  \n",
    "\n",
    "\n",
    "**KNN**  \n",
    "훈  련데이터 RMSE :  53952.69804097723   \n",
    "테스트데이터 RMSE :  63831.91662964773  \n",
    "    \n",
    "**나이브베이즈**  \n",
    "훈  련데이터 RMSE :  64340.34302948542  \n",
    "테스트데이터 RMSE :  63220.68115643447  \n",
    "\n",
    "**인공신경망**  \n",
    "훈  련데이터 RMSE :  184078.00688973855  \n",
    "테스트데이터 RMSE :  183337.3131091806  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15407abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.566197903746314"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인공신경망은 하이퍼파라미터가 매우 다양하여 최적의 조합을 찾는것이 힘들다.\n",
    "# 떄문에 은닉층을 3개(64, 64, 64)로 두어 64개의 노드로 구성된 조금 깊은 신경망모델을 구성해 보겠다.\n",
    "# 또한 활성함수는 relu 로 정하여 분석을 진행하여 본다.\n",
    "\n",
    "# 튜닝 모델\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "model = MLPRegressor(hidden_layer_sizes=(64, 64, 64), activation=\"relu\", random_state=1, max_iter=2000)\n",
    "model.fit(X_scaled_train, y_train)\n",
    "pred_train = model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2cf07dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.584086684313508"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 데이터의 정확도\n",
    "pred_test = model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4e1d417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈  련데이터 RMSE :  62863.255358058195\n",
      "테스트데이터 RMSE :  61654.37310884089\n"
     ]
    }
   ],
   "source": [
    "# RMSE (Root Mean Squared Error)\n",
    "MSE_train = mean_squared_error(y_train, pred_train)\n",
    "MSE_test = mean_squared_error(y_test, pred_test)\n",
    "print(\"훈  련데이터 RMSE : \", np.sqrt(MSE_train))\n",
    "print(\"테스트데이터 RMSE : \", np.sqrt(MSE_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1457ad9d",
   "metadata": {},
   "source": [
    "**[종합정리]**\n",
    "\n",
    "인공신경망의 다층 퍼셉트론 모델로 분류와 회귀 문제를 다루어 보았다. **다층퍼셉트론은 딥러닝과 동일한 구조 이지만 하이퍼 파라미터가 매우 많고 모델에 대한 깊은 이해가 필요한 모델**이다. <u>실제 다층 퍼셉트론보다 딥러닝을 활용하여 분류와 회귀문제를 수행</u>한다. 기본 설정 모델로는 좋은 결과를 얻기 힘들며, 은닉층과 노드의 수, 활성함수등을 조합할때 좋은 성능을 기대할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9a7505",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
