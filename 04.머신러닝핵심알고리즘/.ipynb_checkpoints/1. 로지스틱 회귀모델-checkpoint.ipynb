{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7fdbcd6",
   "metadata": {},
   "source": [
    "# 1. 로지스틱 회귀모델\n",
    "\n",
    "\n",
    "## 1.1 핵심개념\n",
    "\n",
    "**로지스틱 회귀분석은 종속 변수가 범주형 자료일 경우 이용하는 회귀 모델**입니다. \n",
    "종속변수가 범주형일경우 로지스틱 회귀 모델을 적용해보면 일정간 로그곡선이 그려지며 특정 경향성을 띄게 되는데 이를 로지스틱 곡선(Logistic Curve)이라고 부릅니다.\n",
    "\n",
    "로지스틱 회귀모델의 아이디어는 다음과 같습니다.\n",
    "X축이 소득, Y축이 주택 소유 여부의 원데이터를 가지고 소득 수준이 어느정도 일때 주택을 가지게 되는지를 예측하고자 할때. 일반적인 선형회귀모델을 적용하면 올바른 분석 진행이 불가능 합니다.\n",
    "\n",
    "\n",
    "하지만, <u>X축을 소득이 아닌 소득별 구간으로 그리고 Y축을 주택 소유 여부가 아닌 구간별 주택 소유 비율로 대체하였더니 부드러운 S 자 모형의 곡선이 생성되어 구간별 주택 소유 비율을 예측 가능 할 수 있었는데. 이것이 기본적인 로지스틱 회귀모델의 아이디어</u> 입니다.\n",
    "\n",
    "즉, **주택 소유 여부와 같이 범주형 레이블은 예측 함수를 바로 제작하기 어렵기 때문에. 여부를 -> 소유비율로 변환하여 사용한다는 것**입니다. 이러면 3차식과 같은 모델이 나타나며 X변화에 따른 Y의 값을 구간별로 추정 가능하게 됩니다.\n",
    "\n",
    "하지만 이렇게 변환된 데이터에도 약간의 문제가 있었는데. 비율, 즉.확률(Probability)값을 구하는 식이 3차식으로 너무 복잡해 진다는 것 입니다. 때문에 이를 확률 값이 아닌 odds 변환, 그리고 log 를 취해 직선의 형태로 변형하여 분석하기에 이릅니다. 이는 이해하기도 쉬워 지고 분석도 명쾌해지는 장점이 있습니다.\n",
    "\n",
    "즉, **로지스틱 회귀모델은 raw data 를 확률 -> 오즈(Odds) -> 로그(Log) 로 변환하여 선형회귀모델을 적용한 모델**입니다. 그 후 해석은 다시 지수(exp)로 변환하여 raw data로 전환한 모델입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef9098a",
   "metadata": {},
   "source": [
    "## 1.2 scikit-learn\n",
    "\n",
    "파이썬 머신러닝 알고리즘은 사이킷 런에 대부분 담겨 있습니다. 또한 사이킷런 패키지에 대한 상세한 내용은 (https://scikit-learn.org) 에서 확인 가능합니다.\n",
    "\n",
    "\n",
    "**sklearn.linear_model:Linear Models**\n",
    "\n",
    "|Linear classifiers||\n",
    "|:--|:--|\n",
    "|linear_model.LogiscticRegression() |Logistic Regression(aka logit, MaxEnt) clssifier.)|\n",
    "|linear_model.LogisticRegressionCV() |Logistic Regression CV (aka logit, MaxEnt) classifier. |\n",
    "|linear_model.PassiveAggressiveClassifier() |Passive more in the User Guide.|\n",
    "|linear_model.Perceptron() |Read more in the User Guide. |\n",
    "|linear_model.RidgeClassifier() |Classifier using Ridge regression |\n",
    "|linear_model.RidgerClassifierCV() |Ridge classifier with built-in cross-validation. |\n",
    "|linear_model.SGDClassifier() |Linear classifiers.(SVM logistic regression, etc) with SGD training. |\n",
    "\n",
    "\n",
    "LogisticRegression 의 다양한 옵션들 중, 주요 하이퍼 파라미터는 'C' 입니다. 해당 설명을 보면 C 값의 기본 설정은 1입니다. 또한 solver 역시 데이터양에 따른 연산 속도를 결정 짓는 주요 하이퍼 파라미터 입니다.\n",
    "\n",
    "\n",
    "**하이퍼파라미터**\n",
    "\n",
    "|Hyper Parameter ||\n",
    "|--|:--|\n",
    "|C|디폴트 값은 '1'이며 작을 수록 모델이 단순 해지고 값이 커질수록 모델이 복잡해진다.<br/> C는 로그스케일 단위로 최적치 탐색을 권고 하고 있다. (0.01, 0.1, 1, 10, 100 등)|\n",
    "|Solver|solver='sag' <br/> 데이터 양이 수백\\~수십만 건인 경우 풀 배치(full-batch)로 할 경우 시간이 오래 걸리는 점을 보완하기 위해 sovler='sag' 로 설정시 이는 평균 경사 하강법(Stochastic Average Gradient Descent)을 적용하여 빠른 속도로 처리가 가능해진다.|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151dfbbc",
   "metadata": {},
   "source": [
    "## 1.3 분석 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb71c234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['code', 'Clump_Thickness', 'Cell_Size', 'Cell_Shape',\n",
      "       'Marginal_Adhesion', 'Single_Epithelial_Cell_Size', 'Bare_Nuclei',\n",
      "       'Bland_Chromatin', 'Normal_Nucleoli', 'Mitoses', 'Class'],\n",
      "      dtype='object')\n",
      "Class    0.349609\n",
      "dtype: float64\n",
      "Class    0.350877\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 경고레벨조정\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 데이터 로드\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"./extrafiles/breast-cancer-wisconsin.csv\", encoding='utf-8')\n",
    "\n",
    "# 컬럼정보 확인\n",
    "print(data.columns)\n",
    "\n",
    "# 독립변수/ 종속변수 분리\n",
    "X = data[['Clump_Thickness', 'Cell_Size', 'Cell_Shape',\n",
    "       'Marginal_Adhesion', 'Single_Epithelial_Cell_Size', 'Bare_Nuclei',\n",
    "       'Bland_Chromatin', 'Normal_Nucleoli', 'Mitoses']]\n",
    "y = data[['Class']]\n",
    "\n",
    "# train-test data 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "# stratify 효과 - 범주형 변수를 유사한 비율로 train / test 데이터로 분리시켜 준다.\n",
    "print(y_train.mean())\n",
    "print(y_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d82c7f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97265625"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 표준화 작업 - MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_scaled_train = scaler.transform(X_train)\n",
    "X_scaled_test = scaler.transform(X_test)\n",
    "\n",
    "# 로지스틱 회귀 모형 적용\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_scaled_train, y_train)\n",
    "\n",
    "# 훈련데이터의 예측값 생성\n",
    "pred_train = model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a65b75d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련데이터 오차행렬:\n",
      " [[328   5]\n",
      " [  9 170]]\n"
     ]
    }
   ],
   "source": [
    "# 훈련데이터의 오차행렬\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_train = confusion_matrix(y_train, pred_train)\n",
    "print(\"훈련데이터 오차행렬:\\n\", confusion_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee9c106",
   "metadata": {},
   "source": [
    "![혼동행렬](./extrafiles/matrix.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66c0e45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류예측 레포트:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       333\n",
      "           1       0.97      0.95      0.96       179\n",
      "\n",
      "    accuracy                           0.97       512\n",
      "   macro avg       0.97      0.97      0.97       512\n",
      "weighted avg       0.97      0.97      0.97       512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 훈련데이터의 분류 레포트 작성\n",
    "from sklearn.metrics import classification_report\n",
    "cfreport_train = classification_report(y_train, pred_train)\n",
    "print(\"분류예측 레포트:\\n\", cfreport_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be3bb64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9590643274853801"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 데이터의 예측률 계산\n",
    "pred_test = model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2969ad08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 오차행렬:\n",
      " [[106   5]\n",
      " [  2  58]]\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터의 혼동행렬 작성\n",
    "confusion_test = confusion_matrix(y_test, pred_test)\n",
    "print(\"테스트 데이터 오차행렬:\\n\", confusion_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2380c031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류예측 레포트:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97       111\n",
      "           1       0.92      0.97      0.94        60\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.95      0.96      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터의 분류 레포트 작성\n",
    "cfreport_test = classification_report(y_test, pred_test)\n",
    "print(\"분류예측 레포트:\\n\", cfreport_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17b5bada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100]})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 하이퍼 파라미터 튜닝 - Grid Search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C':[0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "grid_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4242f36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter : {'C': 10}\n",
      "Best Score : 0.9726\n",
      "Test set Score : 0.9591\n"
     ]
    }
   ],
   "source": [
    "# 파라미터 튜닝 결과 확인\n",
    "print(\"Best Parameter : {}\".format(grid_search.best_params_))\n",
    "print(\"Best Score : {:.4f}\".format(grid_search.best_score_))\n",
    "print(\"Test set Score : {:.4f}\".format(grid_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d164c8b",
   "metadata": {},
   "source": [
    "**그리드서치**\n",
    "- 로지스틱 회귀의 최적의 파라미터 (C value) 튜닝 값은 10 이며, 예측율은 97.26에 해당 된다.\n",
    "- 테스트 데이터를 이용한 예측률도 95.91%에 달한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cce9bf20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=LogisticRegression(), n_iter=100,\n",
       "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000025B93DFF6D0>})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 하이퍼 파라미터 튜닝2 - Randomized Search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "param_distribs = {'C': randint(low=0.001, high=100)}\n",
    "random_search = RandomizedSearchCV(LogisticRegression(), param_distributions = param_distribs, n_iter=100, cv=5)\n",
    "random_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de28b7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter : {'C': 12}\n",
      "Best Score : 0.9745\n",
      "Test set Score : 0.9591\n"
     ]
    }
   ],
   "source": [
    "# 파라미터 튜닝 결과값 확인\n",
    "print(\"Best Parameter : {}\".format(random_search.best_params_))\n",
    "print(\"Best Score : {:.4f}\".format(random_search.best_score_))\n",
    "print(\"Test set Score : {:.4f}\".format(random_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cd6e06",
   "metadata": {},
   "source": [
    "**랜덤 서치**\n",
    "- 로지스틱 회귀의 최적의 파라미터 (C value) 튜닝 값은 12 이며, 예측율은 97.45%에 해당 된다.\n",
    "- 테스트 데이터를 이용한 예측률도 95.91%에 달한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f87e22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
