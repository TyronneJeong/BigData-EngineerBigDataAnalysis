{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0620c0e3",
   "metadata": {},
   "source": [
    "# 7. 랜덤 포레스트\n",
    "\n",
    "## 7.1 핵심 개념\n",
    "\n",
    "**랜덤포레스트(random forest) 는 학습 데이터를 이용하여 여러 의사결정트리를 생성한 후, 해당 결과를 종합하여 결과를 도출하는 앙상블 기법**입니다. 즉, 랜덤포레스트는 의사결정 나무 수십~수백개가 예측한 분류 혹은 회귀분석 값의 평균을 구해내는 모델입니다. <u>학습 데이터는 무작위로 샘플링 되며 다수의 의사결정 트리로 분석 되기 때문에 랜덤 포레스트라는 이름이 붙었습니다.</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc2eb19",
   "metadata": {},
   "source": [
    "![랜덤포레스트](./extrafiles/randomforest.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327fb749",
   "metadata": {},
   "source": [
    "**[데이터 샘플링 하는 과정]**\n",
    "\n",
    "1. 데이터에서 부트스트래핑 과정을 통해 N개의 샘플링 데이터 셋을 생성  \n",
    "   ㄴ 부트스트랩(핑) : 현재 상황에서 어떻게든 한다는 의미로 컴퓨터 용어로는 더 복잡한 도구를 만들수 있도록 도와주는 단순 도구 또는 그러한 작업을 지칭한다.\n",
    "2. 각 샘플링된 데이터 셋에서 임의의 변수 선택. (sqrt(M)개 또는 M/3 개)\n",
    "3. 의사결정트리들을 종합하여 앙상블 모델을 만들고 OOB Error 를 통해 오분류율을 평가  \n",
    "   ㄴ OOB Error(Out-of-bag Error)  \n",
    "      ㄴ OOB 데이터는 부트스트랩을 통한 데이터를 추출 했을때 train 데이터에 속하지 않은 데이터들을 의미.  \n",
    "      ㄴ OOB Error 는 부트스트랩에 포함되지 않은 데이터들의 Decision Tree 처리결과 나온 예측값과 실제값의 차이를 의미."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f38335e",
   "metadata": {},
   "source": [
    "## 7.2 scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa3642c",
   "metadata": {},
   "source": [
    "**랜덤 포레스트는 sklearn.ensemble 패키지**에 속해 있다. **분류 알고리즘으로는 RandomeForestClassifier**, **회귀분석 알고리즘으로는 RandomForestRegressor** 가 있다.\n",
    "\n",
    "|sklearn.ensemble|Ensemble Methods|\n",
    "|:--|:--|\n",
    "|skleanr.ensemble.AdaBoostClassifier() |An AdaBoost classifier. |\n",
    "|skleanr.ensemble.AdaBoostRegressor() |An AdaBoost regressor. |\n",
    "|skleanr.ensemble.BaggingClassifier() |A Bagging classifier. |\n",
    "|skleanr.ensemble.BaggingRegressor() |A Bagging regressor. |\n",
    "|skleanr.ensemble.ExtraTreeClassifier() |An extra-tree classifier. |\n",
    "|skleanr.ensemble.ExtraTreeRegressor() |An extra-tree regressor. |\n",
    "|skleanr.ensemble.GradientBoostingClassifier() |Gradient Boosting for classification. |\n",
    "|skleanr.ensemble.GradientBoostingRegressor() |Gradient Boosting for regressor.|\n",
    "|skleanr.ensemble.IsolationForest() |Isolation Forest Algorithm. |\n",
    "|skleanr.ensemble.RandomForestClassifier() |A random forest classifier. |\n",
    "|skleanr.ensemble.RandomForestRegressor() |A random forest regressor. |\n",
    "|skleanr.ensemble.RandomTreeEmbedding() |An ensemble of totally random trees.|\n",
    "|skleanr.ensemble.StackingClassifier() |Stack of estimators with a final classifier.|\n",
    "|skleanr.ensemble.StackingRegressor() |Stack of esimators with a final regressor. |\n",
    "\n",
    "랜덤포레스의 분로와 회귀 기본 디폴트 옵션은 거의 동일합니다. 다만 의사 결정나무와 마찬가지로 **분류 모델의 경우 기준(criterion)은 'gini' 이고 회귀 분석 모델의 기준은 mse** 가 됩니다.\n",
    "\n",
    "|Hyper Parameter||\n",
    "|:--|:--|\n",
    "|n_estimators|랜덤포레스트를 구성하는 의사경정트리의 수 (기본값:100|\n",
    "|max_features|의사결정트리에 적용되는 특성변수의 수<br/>- \"auto\"/\"sqrt\" : sqrt(n_features)<br/>- \"log2\" : log2(n_features)<br/>- \"none\" : n_features|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60e6b47",
   "metadata": {},
   "source": [
    "## 7.3 분석 코드\n",
    "\n",
    "### Part1. 분류(Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c063fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['code', 'Clump_Thickness', 'Cell_Size', 'Cell_Shape',\n",
      "       'Marginal_Adhesion', 'Single_Epithelial_Cell_Size', 'Bare_Nuclei',\n",
      "       'Bland_Chromatin', 'Normal_Nucleoli', 'Mitoses', 'Class'],\n",
      "      dtype='object')\n",
      "Class    0.349609\n",
      "dtype: float64\n",
      "Class    0.350877\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 경고레벨조정\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 데이터 로드\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"./extrafiles/breast-cancer-wisconsin.csv\", encoding='utf-8')\n",
    "\n",
    "# 컬럼정보 확인\n",
    "print(data.columns)\n",
    "\n",
    "# 독립변수/ 종속변수 분리\n",
    "X = data[['Clump_Thickness', 'Cell_Size', 'Cell_Shape',\n",
    "       'Marginal_Adhesion', 'Single_Epithelial_Cell_Size', 'Bare_Nuclei',\n",
    "       'Bland_Chromatin', 'Normal_Nucleoli', 'Mitoses']]\n",
    "y = data[['Class']]\n",
    "\n",
    "# train-test data 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "# stratify 효과 - 범주형 변수를 유사한 비율로 train / test 데이터로 분리시켜 준다.\n",
    "print(y_train.mean())\n",
    "print(y_test.mean())\n",
    "\n",
    "# 표준화 작업 - MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_scaled_train = scaler.transform(X_train)\n",
    "X_scaled_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eefef31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_scaled_train, y_train)\n",
    "pred_train = model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14d100f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련데이터 오차행렬 : \n",
      " [[333   0]\n",
      " [  0 179]]\n"
     ]
    }
   ],
   "source": [
    "# 훈련데이터의 혼동행렬 작성\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_train = confusion_matrix(y_train, pred_train)\n",
    "print(\"훈련데이터 오차행렬 : \\n\", confusion_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8032791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류예측 레포트 : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       333\n",
      "           1       1.00      1.00      1.00       179\n",
      "\n",
      "    accuracy                           1.00       512\n",
      "   macro avg       1.00      1.00      1.00       512\n",
      "weighted avg       1.00      1.00      1.00       512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 훈련데이터의 분류 레포트 작성\n",
    "from sklearn.metrics import classification_report\n",
    "cfreport_train = classification_report(y_train, pred_train)\n",
    "print(\"분류예측 레포트 : \\n\", cfreport_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87667fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649122807017544"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트데이터 예측결과 생성\n",
    "pred_test = model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68e86431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트데이터 오차행렬 : \n",
      " [[106   5]\n",
      " [  1  59]]\n"
     ]
    }
   ],
   "source": [
    "# 테스트데이터의 혼동행렬 작성\n",
    "confusion_test = confusion_matrix(y_test, pred_test)\n",
    "print(\"테스트데이터 오차행렬 : \\n\", confusion_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18fe2f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류예측 레포트 : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       111\n",
      "           1       0.92      0.98      0.95        60\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.96      0.97      0.96       171\n",
      "weighted avg       0.97      0.96      0.97       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 테스트데이터의 분류 레포트 작성\n",
    "from sklearn.metrics import classification_report\n",
    "cfreport_test = classification_report(y_test, pred_test)\n",
    "print(\"분류예측 레포트 : \\n\", cfreport_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e444e743",
   "metadata": {},
   "source": [
    "의사결정트리와는 달리 훈련용 데이터 테스트 데이터 모두 높은 예측율을 보여주고 있다. 즉 과적합 되지는 않았다는 의미이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "280488ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': range(100, 1000, 100)})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 하이퍼 파라미터 튜닝 - Grid Search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'n_estimators' :range(100, 1000, 100), \n",
    "              'max_features' :['auto', 'sqrt', 'log2']}\n",
    "             \n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
    "grid_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef299eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter : {'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Best Score : 0.9746\n",
      "Test set Score : 0.9649\n"
     ]
    }
   ],
   "source": [
    "# 파라미터 튜닝 결과 확인\n",
    "print(\"Best Parameter : {}\".format(grid_search.best_params_))\n",
    "print(\"Best Score : {:.4f}\".format(grid_search.best_score_))\n",
    "print(\"Test set Score : {:.4f}\".format(grid_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b45503e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=20,\n",
       "                   param_distributions={'max_features': ['auto', 'sqrt',\n",
       "                                                         'log2'],\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002134B4BF430>})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 하이퍼 파라미터 튜닝2 - Randomized Search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_distribs = {'n_estimators' :randint(low=100, high=1000), \n",
    "                  'max_features' :['auto', 'sqrt', 'log2']}\n",
    "\n",
    "random_search = RandomizedSearchCV(RandomForestClassifier(), param_distributions=param_distribs, n_iter=20, cv=5)\n",
    "random_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6012356b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter : {'max_features': 'log2', 'n_estimators': 599}\n",
      "Best Score : 0.9746\n",
      "Test set Score : 0.9649\n"
     ]
    }
   ],
   "source": [
    "# 파라미터 튜닝 결과값 확인\n",
    "print(\"Best Parameter : {}\".format(random_search.best_params_))\n",
    "print(\"Best Score : {:.4f}\".format(random_search.best_score_))\n",
    "print(\"Test set Score : {:.4f}\".format(random_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca569b3",
   "metadata": {},
   "source": [
    "### Part2. 회귀(Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "827b5f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['housing_age', 'income', 'bedrooms', 'households', 'rooms',\n",
      "       'house_value'],\n",
      "      dtype='object')\n",
      "Index(['income', 'bedrooms', 'households', 'rooms'], dtype='object')\n",
      "house_value    189260.967812\n",
      "dtype: float64\n",
      "house_value    188391.001357\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "data2 = pd.read_csv('./extrafiles/house_price.csv', encoding='utf-8')\n",
    "\n",
    "print(data2.columns)\n",
    "\n",
    "X = data2[data2.columns[1:5]]\n",
    "y = data2[['house_value']]\n",
    "\n",
    "print(X.columns)\n",
    "\n",
    "# train-test data 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# stratify 효과 - 범주형 변수를 유사한 비율로 train / test 데이터로 분리시켜 준다.\n",
    "print(y_train.mean())\n",
    "print(y_test.mean())\n",
    "\n",
    "# 표준화 작업 - MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_scaled_train = scaler.transform(X_train)\n",
    "X_scaled_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5506538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9380740281242856"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 의사결정트리 모델 적용\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_scaled_train, y_train)\n",
    "pred_train = model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1412935b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5841233859621466"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 데이터 모델 적용\n",
    "pred_test = model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6248361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈  련데이터 RMSE: 23751.30406433138\n",
      "테스트데이터 RMSE: 61651.652749843626\n"
     ]
    }
   ],
   "source": [
    "# 회귀분석의 지표 R Square n RMSE\n",
    "# RMSE (Root Mean Squared Error)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "MSE_train = mean_squared_error(y_train, pred_train)\n",
    "MSE_test = mean_squared_error(y_test, pred_test)\n",
    "print(\"훈  련데이터 RMSE:\", np.sqrt(MSE_train))\n",
    "print(\"테스트데이터 RMSE:\", np.sqrt(MSE_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebfc2e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid={'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': range(100, 500, 100)})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 하이퍼 파라미터 튜닝 - Grid Search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'n_estimators' :range(100, 500, 100), \n",
    "              'max_features' :['auto', 'sqrt', 'log2']}\n",
    "grid_search = GridSearchCV(RandomForestRegressor(), param_grid, cv=5)\n",
    "grid_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07240b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter : {'max_features': 'log2', 'n_estimators': 400}\n",
      "Best Score : 0.5687\n",
      "Test set Score : 0.5933\n"
     ]
    }
   ],
   "source": [
    "# 파라미터 튜닝 결과 확인\n",
    "print(\"Best Parameter : {}\".format(grid_search.best_params_))\n",
    "print(\"Best Score : {:.4f}\".format(grid_search.best_score_))\n",
    "print(\"Test set Score : {:.4f}\".format(grid_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29b98ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_iter=20,\n",
       "                   param_distributions={'max_features': ['auto', 'sqrt',\n",
       "                                                         'log2'],\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002134C569F40>})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 하이퍼 파라미터 튜닝2 - Randomized Search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_distribs = {'n_estimators' :randint(low=100, high=500), \n",
    "                  'max_features' :['auto', 'sqrt', 'log2']}\n",
    "\n",
    "random_search = RandomizedSearchCV(RandomForestRegressor(), param_distributions=param_distribs, n_iter=20, cv=5)\n",
    "random_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7dbaea98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter : {'max_features': 'sqrt', 'n_estimators': 439}\n",
      "Best Score : 0.5688\n",
      "Test set Score : 0.5930\n"
     ]
    }
   ],
   "source": [
    "# 파라미터 튜닝 결과값 확인\n",
    "print(\"Best Parameter : {}\".format(random_search.best_params_))\n",
    "print(\"Best Score : {:.4f}\".format(random_search.best_score_))\n",
    "print(\"Test set Score : {:.4f}\".format(random_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ad9ece",
   "metadata": {},
   "source": [
    "**[종합정리]**\n",
    "\n",
    "**랜덤포레스트의 경우 하이퍼 파라미터가 튜닝되지 않은 상태에서는 과적합 경향**을 보였습니다만, <u>적절한 모델수와 특성치를 탐색한 결과는 좋은 결과를 나타내고 있으며, 다른 앙상블 기법들보다 단순한 구조이면서 강력한 성능</u>을 보입니다. 때문에 실전 분석에서 가장 많이 사용되는 알고리즘중 하나가 랜덤 포레스트 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703581dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
