{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0c2bcf0",
   "metadata": {},
   "source": [
    "# 6. 의사결정나무\n",
    "\n",
    "## 6.1 핵심 개념\n",
    "\n",
    "**의사결정나무(decision tree)는 의사결정 규칙을 나무구조로 도표화 하여 관심 대상이 되는 집단을 몇 개의 소집단으로 분류 하거나 특정값을 예측하는데 활용되는 분석기법**이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9681d433",
   "metadata": {},
   "source": [
    "![의사결정나무](./extrafiles/decisiontree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cbac6b",
   "metadata": {},
   "source": [
    "**[구성요소]**\n",
    "\n",
    "![트리](./extrafiles/tree.png)\n",
    "\n",
    "|구성요소\t|설명|\n",
    "|:--|:--|\n",
    "|뿌리 마디(Root Node)\t|나무가 시작되는 마디로 전체 자료를 포함|\n",
    "|중간 마디(InternalNode)|\t부모와 자식 마디를 모두 가진 마디|\n",
    "|끝 마디(Terminal Node)\t|자식 노드가 없는 마디|\n",
    "|부모 마디(Parent Node)\t|주어진 노드의 상위 마디|\n",
    "|자식 마디(Child Node)\t|주어진 노드의 하위 마디|\n",
    "|가지(Branch)\t|하나의 마디로부터 끝 마디까지 연결된 마디들|\n",
    "|깊이(Depth)\t|가지를 이루는 마디의 개수|\n",
    "\n",
    "**[주요특징]**  \n",
    "\n",
    "**의사결정트리는 직관적으로 결과를 도식화 하여 볼 수 있다는 장점**이 있습니다. 그러나 <u>분류 단계가 증가할 수록 트리는 복잡해지며 데이터에 따라 안정적인 결과도출이 힘들어 짐에 따라 머신러닝 알고리즘으로 많이 활용되지는 않습니다.</u> 하지만 특성치가 많지 않고 최종 알고리즘을 도출하기 전 탐색적으로 주요 변수가 어떤것인지를 도출 하는 차원에서는 활용 하기 좋은 알고리즘입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3675be4",
   "metadata": {},
   "source": [
    "## 6.2 scikit-learn\n",
    "\n",
    "**의사결정나무는 sklearn.tree 패키지**에 속해 있습니다. **DecisionTreeClassifier 는 분류 알고리즘**이며, **DecisionTreeRegressor 는 회귀분석 알고리즘**입니다.\n",
    "\n",
    "\n",
    "|sklearn.tree|Decision Trees|\n",
    "|:--|:--|\n",
    "|sklearn.tree.DecisionTreeClassifier() |A decision tree classifier. |\n",
    "|sklearn.tree.DecisionTreeRegressor() |A decision tree regressor. |\n",
    "|sklearn.tree.ExtraTreeClassifier() |An extremely randomized tree classifier. |\n",
    "|sklearn.tree.ExtraTreeRegressor() |An extremely randomized tree regressor. |\n",
    "\n",
    "\n",
    "의사결정나무의 하이퍼 파라미터중 분류나 회귀 결과에 영향을 미치는 것은 **max_depth, max_leaf_node, min_sample_leaf** 입니다.\n",
    "\n",
    "|Hyper Parameter||\n",
    "|:--|:--|\n",
    "|max_depth|최대 가지치기의 수|\n",
    "|max_leaf_node|리프 노드의 최대 개수|\n",
    "|max_sample_leaf|리프 노트가 되기 위한 최소 샘플 수|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea96163f",
   "metadata": {},
   "source": [
    "## 6.3 분석 코드\n",
    "\n",
    "### Part1. 분류(Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "996db74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['code', 'Clump_Thickness', 'Cell_Size', 'Cell_Shape',\n",
      "       'Marginal_Adhesion', 'Single_Epithelial_Cell_Size', 'Bare_Nuclei',\n",
      "       'Bland_Chromatin', 'Normal_Nucleoli', 'Mitoses', 'Class'],\n",
      "      dtype='object')\n",
      "Class    0.349609\n",
      "dtype: float64\n",
      "Class    0.350877\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 경고레벨조정\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 데이터 로드\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"./extrafiles/breast-cancer-wisconsin.csv\", encoding='utf-8')\n",
    "\n",
    "# 컬럼정보 확인\n",
    "print(data.columns)\n",
    "\n",
    "# 독립변수/ 종속변수 분리\n",
    "X = data[['Clump_Thickness', 'Cell_Size', 'Cell_Shape',\n",
    "       'Marginal_Adhesion', 'Single_Epithelial_Cell_Size', 'Bare_Nuclei',\n",
    "       'Bland_Chromatin', 'Normal_Nucleoli', 'Mitoses']]\n",
    "y = data[['Class']]\n",
    "\n",
    "# train-test data 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "# stratify 효과 - 범주형 변수를 유사한 비율로 train / test 데이터로 분리시켜 준다.\n",
    "print(y_train.mean())\n",
    "print(y_test.mean())\n",
    "\n",
    "# 표준화 작업 - MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_scaled_train = scaler.transform(X_train)\n",
    "X_scaled_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2b3f5a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_scaled_train, y_train)\n",
    "pred_train = model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e28c9868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련데이터 오차행렬 : \n",
      " [[333   0]\n",
      " [  0 179]]\n"
     ]
    }
   ],
   "source": [
    "# 훈련데이터의 혼동행렬 작성\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_train = confusion_matrix(y_train, pred_train)\n",
    "print(\"훈련데이터 오차행렬 : \\n\", confusion_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5df026c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류예측 레포트 : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       333\n",
      "           1       1.00      1.00      1.00       179\n",
      "\n",
      "    accuracy                           1.00       512\n",
      "   macro avg       1.00      1.00      1.00       512\n",
      "weighted avg       1.00      1.00      1.00       512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 훈련데이터의 분류 레포트 작성\n",
    "from sklearn.metrics import classification_report\n",
    "cfreport_train = classification_report(y_train, pred_train)\n",
    "print(\"분류예측 레포트 : \\n\", cfreport_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd8ceb8",
   "metadata": {},
   "source": [
    "훈련데이터의 정확도는 100%에 해당한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc6b2c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9532163742690059"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트데이터 예측결과 생성\n",
    "pred_test = model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63ead203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트데이터 오차행렬 : \n",
      " [[105   6]\n",
      " [  2  58]]\n"
     ]
    }
   ],
   "source": [
    "# 테스트데이터의 혼동행렬 작성\n",
    "confusion_test = confusion_matrix(y_test, pred_test)\n",
    "print(\"테스트데이터 오차행렬 : \\n\", confusion_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f71180cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류예측 레포트 : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96       111\n",
      "           1       0.91      0.97      0.94        60\n",
      "\n",
      "    accuracy                           0.95       171\n",
      "   macro avg       0.94      0.96      0.95       171\n",
      "weighted avg       0.95      0.95      0.95       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 테스트데이터의 분류 레포트 작성\n",
    "from sklearn.metrics import classification_report\n",
    "cfreport_test = classification_report(y_test, pred_test)\n",
    "print(\"분류예측 레포트 : \\n\", cfreport_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ec12d5",
   "metadata": {},
   "source": [
    "테스트데이터의 정확도는 95.3%에 해당된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f7bdab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'max_depth': range(2, 20, 2),\n",
       "                         'min_samples_leaf': range(1, 50, 2)})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 하이퍼 파라미터 튜닝 - Grid Search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'max_depth'        :range(2, 20, 2), \n",
    "              'min_samples_leaf' :range(1, 50, 2)}\n",
    "             \n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5)\n",
    "grid_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29145f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter : {'max_depth': 18, 'min_samples_leaf': 1}\n",
      "Best Score : 0.9667\n",
      "Test set Score : 0.9474\n"
     ]
    }
   ],
   "source": [
    "# 파라미터 튜닝 결과 확인\n",
    "print(\"Best Parameter : {}\".format(grid_search.best_params_))\n",
    "print(\"Best Score : {:.4f}\".format(grid_search.best_score_))\n",
    "print(\"Test set Score : {:.4f}\".format(grid_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d03f3c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_iter=20,\n",
       "                   param_distributions={'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000017172F7B790>,\n",
       "                                        'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000017176915E20>})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 하이퍼 파라미터 튜닝2 - Randomized Search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_distribs = {'max_depth'        :randint(low=1, high=20), \n",
    "                  'min_samples_leaf' :randint(low=1, high=50)}\n",
    "\n",
    "random_search = RandomizedSearchCV(DecisionTreeClassifier(), param_distributions=param_distribs, n_iter=20, cv=5)\n",
    "random_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "027f060a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter : {'max_depth': 15, 'min_samples_leaf': 6}\n",
      "Best Score : 0.9531\n",
      "Test set Score : 0.9591\n"
     ]
    }
   ],
   "source": [
    "# 파라미터 튜닝 결과값 확인\n",
    "print(\"Best Parameter : {}\".format(random_search.best_params_))\n",
    "print(\"Best Score : {:.4f}\".format(random_search.best_score_))\n",
    "print(\"Test set Score : {:.4f}\".format(random_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a8f77c",
   "metadata": {},
   "source": [
    "[종합정리]\n",
    "\n",
    "**의사결정나무는 학습데이터에 매우 과정합되는 경향**이 있습니다. 앞선 100% 예측율에 비해 테스트 데이터에서는 95% 예측율로 낮아지는것이 그 예입니다. 또한 **하이퍼 파라미터 설정에 대한 기준 역시 논리적으로 추론하기가 어렵**습니다. 이러한 한계에도 불구하고 의사결정 트리는 <u>기본적인 분석 방향을 탐색하기 위한 초기 분석 모델로서는 유용</u>합니다. 실제 분석에서는 의사결정나무와 앙상블된 랜덤 포레스트가 주로 사용됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fca13b",
   "metadata": {},
   "source": [
    "### Part2. 회귀(Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6623bb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['housing_age', 'income', 'bedrooms', 'households', 'rooms',\n",
      "       'house_value'],\n",
      "      dtype='object')\n",
      "Index(['income', 'bedrooms', 'households', 'rooms'], dtype='object')\n",
      "house_value    189260.967812\n",
      "dtype: float64\n",
      "house_value    188391.001357\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "data2 = pd.read_csv('./extrafiles/house_price.csv', encoding='utf-8')\n",
    "\n",
    "print(data2.columns)\n",
    "\n",
    "X = data2[data2.columns[1:5]]\n",
    "y = data2[['house_value']]\n",
    "\n",
    "print(X.columns)\n",
    "\n",
    "# train-test data 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# stratify 효과 - 범주형 변수를 유사한 비율로 train / test 데이터로 분리시켜 준다.\n",
    "print(y_train.mean())\n",
    "print(y_test.mean())\n",
    "\n",
    "# 표준화 작업 - MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_scaled_train = scaler.transform(X_train)\n",
    "X_scaled_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "817bdacc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 의사결정트리 모델 적용\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model = DecisionTreeRegressor()\n",
    "model.fit(X_scaled_train, y_train)\n",
    "pred_train = model.predict(X_scaled_train)\n",
    "model.score(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ae4a1a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21465026278419952"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 데이터 모델 적용\n",
    "pred_test = model.predict(X_scaled_test)\n",
    "model.score(X_scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f387c6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈  련데이터 RMSE: 0.0\n",
      "테스트데이터 RMSE: 84721.57586552504\n"
     ]
    }
   ],
   "source": [
    "# 회귀분석의 지표 R Square n RMSE\n",
    "# RMSE (Root Mean Squared Error)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "MSE_train = mean_squared_error(y_train, pred_train)\n",
    "MSE_test = mean_squared_error(y_test, pred_test)\n",
    "print(\"훈  련데이터 RMSE:\", np.sqrt(MSE_train))\n",
    "print(\"테스트데이터 RMSE:\", np.sqrt(MSE_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dec45fd",
   "metadata": {},
   "source": [
    "훈련 데이터의 오차율이 0인것에 비래 테스트 데이터에서는 그 차이가 많이 납니다. 이것은 **훈련데이터에 과적합(overfitting)된 예**라고 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3e42654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeRegressor(),\n",
       "             param_grid={'max_depth': range(2, 20, 2),\n",
       "                         'min_samples_leaf': range(1, 50, 2)})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 하이퍼 파라미터 튜닝 - Grid Search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'max_depth'        :range(2, 20, 2), \n",
    "              'min_samples_leaf' :range(1, 50, 2)}\n",
    "grid_search = GridSearchCV(DecisionTreeRegressor(), param_grid, cv=5)\n",
    "grid_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3deedcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter : {'max_depth': 8, 'min_samples_leaf': 49}\n",
      "Best Score : 0.5592\n",
      "Test set Score : 0.5770\n"
     ]
    }
   ],
   "source": [
    "# 파라미터 튜닝 결과 확인\n",
    "print(\"Best Parameter : {}\".format(grid_search.best_params_))\n",
    "print(\"Best Score : {:.4f}\".format(grid_search.best_score_))\n",
    "print(\"Test set Score : {:.4f}\".format(grid_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f32f13a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=DecisionTreeRegressor(), n_iter=20,\n",
       "                   param_distributions={'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000017176B2D880>,\n",
       "                                        'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000017176B2D2E0>})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 하이퍼 파라미터 튜닝2 - Randomized Search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_distribs = {'max_depth'        :randint(low=1, high=20), \n",
    "                  'min_samples_leaf' :randint(low=1, high=50)}\n",
    "\n",
    "random_search = RandomizedSearchCV(DecisionTreeRegressor(), param_distributions=param_distribs, n_iter=20, cv=5)\n",
    "random_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f1747fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter : {'max_depth': 10, 'min_samples_leaf': 47}\n",
      "Best Score : 0.5576\n",
      "Test set Score : 0.5768\n"
     ]
    }
   ],
   "source": [
    "# 파라미터 튜닝 결과값 확인\n",
    "print(\"Best Parameter : {}\".format(random_search.best_params_))\n",
    "print(\"Best Score : {:.4f}\".format(random_search.best_score_))\n",
    "print(\"Test set Score : {:.4f}\".format(random_search.score(X_scaled_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906264aa",
   "metadata": {},
   "source": [
    "**[종합정리]**\n",
    "\n",
    "회귀분석 문제에서도 과적합 문제가 발생되었습니다. 하지만 **적절한 하이퍼파라미터만 찾는다면 안정적인 예측율을 찾을 수 있고 일반화역시 가능**합니다. <u>다만 항시 하이퍼 파라미터를 기본 값이 아닌 적절값을 설정 해주어야만 합니다.</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d795a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
