{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3b194ac",
   "metadata": {},
   "source": [
    "# Ridge 회귀모델\n",
    "\n",
    "릿지는 선형 회귀분석의 기본원리를 그대로 따르나, 가중치(회귀계수)값을 최대한 작게 만들어, 모든 독립변수가 종속변수에 미치는 영향을 최소화 하는 제약을 반영한 모델이다. 각 특성의 영향을 최소화 하는 것은 훈련데이터에 과대 적합 되지 않도록 하기 위함이다.\n",
    "\n",
    "릿지모델에서는 $\\alpha$ 값이 하이퍼 파라미터 역할을 한다. 이 값은 규제를 강하게 혹은 적게 할지를 정하는 파라미터이다. 0에 가까울수록 규제가 적어진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f6fc16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "# 패키지 로드\n",
    "%reset\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드\n",
    "df = pd.read_csv('./extrafiles/house_price.csv')\n",
    "df\n",
    "\n",
    "# train_test_split\n",
    "X = df[['housing_age', 'income', 'bedrooms', 'households', 'rooms']]\n",
    "y = df[['house_value']]\n",
    "\n",
    "# 통계적 회귀 분석에서는 일반적으로 X데이터의 정규화를 하지 않는다.\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# X_scaled = MinMaxScaler().fit_transform(X)\n",
    "# X_scaled = pd.DataFrame(X_scaled, index=X.index, columns=X.columns)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a78ef357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Value : >>  0.5776889147170632\n",
      "Test Value : >>  0.5612602610304924\n"
     ]
    }
   ],
   "source": [
    "# Ridge 모델 적용\n",
    "from sklearn.linear_model import Ridge\n",
    "model = Ridge(alpha=0.4).fit(X_train, y_train)\n",
    "\n",
    "print(\"Train Value : >> \", model.score(X_train, y_train))\n",
    "print(\"Test Value : >> \", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9fc9734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5회 교차검증 결과 : >> 0.5763936572015432\n"
     ]
    }
   ],
   "source": [
    "# KFold 를 이용하여 일반화 성능을 높여보자\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=444)\n",
    "score = cross_val_score(Ridge(alpha=0.1), X_train, y_train, cv=kfold)\n",
    "\n",
    "print(\"5회 교차검증 결과 : >>\", score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef37bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대략 다 비슷비슷하네.. 정확도를 일정 이상 올리려면 뭘 해야 할까?!?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
